{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MelGAN Imputation.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RC8SQSioe03I"},"source":["# pix2pix\n","\n","Adapted from https://github.com/eriklindernoren/PyTorch-GAN/tree/master/implementations/pix2pix"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ez4lb1DKfJI8","executionInfo":{"status":"ok","timestamp":1622604905742,"user_tz":300,"elapsed":22613,"user":{"displayName":"Noah Schaffer","photoUrl":"","userId":"17735346310720165772"}},"outputId":"49e56de3-8402-4ffd-c260-2dc90c8a1c3e"},"source":["from google.colab import drive\n","import sys\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRcz29iGfWgi","executionInfo":{"status":"ok","timestamp":1622604906948,"user_tz":300,"elapsed":1229,"user":{"displayName":"Noah Schaffer","photoUrl":"","userId":"17735346310720165772"}},"outputId":"b5972176-4892-4066-8be7-e7542e80b28c"},"source":["#Change local path to files and test that it works (change local_path and path in sys.path.append)\n","\n","#Path to Pix2Pix directory\n","local_path = '/content/drive/MyDrive/Pix2Pix/'\n","!ls '{local_path}'\n","\n","#Path to libraries directory\n","sys.path.append('/content/drive/MyDrive/Pix2Pix/libraries')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conda_environment.yml\t\t\timages\t    original_sources\n","demucs_test_separated_flat\t\tlibraries   README.md\n","files\t\t\t\t\tLICENSE.md  results.pkl\n","generative_audio_inpainting_report.pdf\tnotebooks   saves\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-TfGRtPIe03Q"},"source":["import os\n","import numpy as np\n","import math\n","import itertools\n","import time\n","import datetime\n","import sys\n","import pickle\n","from multiprocessing import Pool\n","import resource\n","from tqdm import tqdm\n","\n","\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","\n","#from models.pix2pix import *\n","from models.MelGAN import *\n","from models.unet import *\n","from mlp import audio\n","from mlp import normalization\n","from mlp import utils as mlp\n","#from mlp.MelDataset import MusicDataset\n","from mlp.WaveDataset import MusicDataset\n","\n","%load_ext autoreload"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVtqVZqHe03R"},"source":["%matplotlib inline\n","%autoreload"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NO7k27sWe03S"},"source":["epoch = 0 # epoch to start training from\n","n_epochs = 1000 # number of epochs of training\n","dataset_name = 'MUSDB-18' # name of the dataset\n","batch_size = 4 # size of the batches\n","lr = 0.0001 # adam: learning rate\n","b1 = 0.5 # adam: decay of first order momentum of gradient\n","b2 = 0.9 # adam: decay of first order momentum of gradient\n","decay_epoch = 100 # epoch from which to start lr decay\n","n_cpu = 4 # number of cpu threads to use during batch generation\n","img_height = 128 # size of image height\n","img_width = 128 # size of image width\n","channels = 1 # number of image channels\n","sample_interval = 100 # interval between sampling of images from generators\n","checkpoint_interval = 100 # interval between model checkpoints\n","n_layers_D = 4\n","num_D = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SjBxV8Aae03S"},"source":["cuda = True if torch.cuda.is_available() else False\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","resource.setrlimit(resource.RLIMIT_NOFILE, (4096, resource.getrlimit(resource.RLIMIT_NOFILE)[1]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qsI-7suie03T"},"source":["n_mel_channels = 80\n","ngf = 32\n","n_residual_layers = 3\n","\n","num_D = 3\n","ndf = 16\n","n_layers_D = 4\n","downsamp_factor = 4\n","lambda_feat = 10\n","save_interval = 20\n","log_interval = 100\n","\n","netG = GeneratorMel(n_mel_channels, ngf, n_residual_layers).cuda()\n","netD = DiscriminatorMel(\n","        num_D, ndf, n_layers_D, downsamp_factor\n","    ).cuda()\n","fft = Audio2Mel(n_mel_channels=n_mel_channels).cuda()\n","\n","optG = torch.optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n","optD = torch.optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DcjxCxbNU6aw"},"source":["dirty_path ='/content/drive/MyDrive/Pix2Pix/demucs_test_separated_flat'\n","clean_path ='/content/drive/MyDrive/Pix2Pix/original_sources'\n","\n","train_dirty = []\n","train_clean = []\n","val_dirty = []\n","val_clean = []\n","\n","for s in os.listdir(dirty_path):\n","  if np.random.rand() < .8:\n","    train_dirty.append(dirty_path + '/' + s)\n","    train_clean.append(clean_path +'/' + s)\n","  else:\n","    val_dirty.append(dirty_path +'/' + s)\n","    val_clean.append(clean_path + '/' + s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxU97vGle03U"},"source":["fs = 48000\n","bs = batch_size\n","stroke_width = 32\n","patch_width = img_width\n","patch_height = img_height\n","nperseg = 256\n","\n","#train_files = pickle.load(open(local_path+ \"/files/train.pk\", \"rb\"))[:1]\n","#val_files = pickle.load(open(local_path+ \"/files/valid.pk\", \"rb\"))[:1]\n","\n","\n","\n","ds_valid = MusicDataset(val_clean,val_dirty,44100,44100)\n","ds_train = MusicDataset(train_clean,train_dirty,44100,44100)\n","\n","\n","valid_loader = DataLoader(ds_valid, batch_size=bs, num_workers=2, shuffle=False)\n","train_loader = DataLoader(ds_train, batch_size=bs, num_workers=2, shuffle=True)\n","\n","\n","\n","#with Pool(8) as p:\n","#    train_dss = []\n","#    \n","#    for i in range(1):\n","#        train_dss.append(WAVAudioDS(train_files[i*4000:(i+1)*4000], mk_source=lambda x: x * purge_mask, \n","#                                    preprocess=preprocess, patch_width=patch_width, proc_pool=p, \n","#                                    nperseg=256, random_patches=True))\n","\n","#    ds_train = MultiSet(train_dss)\n","#    ds_test = WAVAudioDS(val_files, mk_source=lambda x: x * purge_mask, preprocess=preprocess, \n","#                          patch_width=patch_width, proc_pool=p, nperseg=256, random_patches=False)\n","\n","#val_dataloader = DataLoader(ds_train, batch_size=bs, num_workers=8, shuffle=True)\n","#dataloader = DataLoader(ds_test, batch_size=bs, num_workers=8, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q6hURA1qe03X"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"LteDsPFBe03Y"},"source":["from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter()\n","costs = []\n","start = time.time()\n","\n","#prev_time = time.time()\n","results = []\n","#real_A = torch.from_numpy(ds_train[0][0]).unsqueeze(0).unsqueeze(1).to(device)\n","#real_B = torch.from_numpy(ds_train[0][1]).unsqueeze(0).unsqueeze(1).to(device)\n","\n","dis_train = 0\n","steps = 0\n","for epoch in range(200, n_epochs):\n","    if epoch % 100 == 0:\n","      torch.save(netG.state_dict(), local_path +'saves/' +  str(epoch) + \"netG.pt\")\n","      torch.save(writer, local_path +'saves/' +  str(epoch) + \"writer\")\n","    for iterno, x_t in enumerate(train_loader):\n","          x_t_0 = x_t[0].unsqueeze(1).float().cuda()\n","          x_t_1 = x_t[1].unsqueeze(1).float().cuda()\n","          s_t = fft(x_t_0).detach()\n","          x_pred_t = netG(s_t.cuda())\n","          with torch.no_grad():\n","              s_pred_t = fft(x_pred_t.detach())\n","              s_error = F.l1_loss(s_t, s_pred_t).item()\n","\n","            #######################\n","            # Train Discriminator #\n","            #######################\n","\n","\n","          \n","          x_t_1 = x_t_1[:,:,:44032]\n","          D_fake_det = netD(x_pred_t.cuda().detach())\n","          D_real = netD(x_t_1.cuda())\n","\n","          loss_D = 0\n","          for scale in D_fake_det:\n","              loss_D += F.relu(1 + scale[-1]).mean()\n","\n","          for scale in D_real:\n","              loss_D += F.relu(1 - scale[-1]).mean()\n","\n","          netD.zero_grad()\n","          loss_D.backward()\n","          optD.step()\n","\n","            ###################\n","            # Train Generator #\n","            ###################\n","          D_fake = netD(x_pred_t.cuda())\n","\n","          loss_G = 0\n","          for scale in D_fake:\n","              loss_G += -scale[-1].mean()\n","\n","          loss_feat = 0\n","          feat_weights = 4.0 / (n_layers_D + 1)\n","          D_weights = 1.0 / num_D\n","          wt = D_weights * feat_weights\n","          for i in range(num_D):\n","              for j in range(len(D_fake[i]) - 1):\n","                  loss_feat += wt * F.l1_loss(D_fake[i][j], D_real[i][j].detach())\n","\n","          netG.zero_grad()\n","          (loss_G + lambda_feat * loss_feat).backward()\n","          optG.step()\n","\n","            ######################\n","            # Update tensorboard #\n","            ######################\n","          costs.append([loss_D.item(), loss_G.item(), loss_feat.item(), s_error])\n","\n","          writer.add_scalar(\"loss/discriminator\", costs[-1][0], steps)\n","          writer.add_scalar(\"loss/generator\", costs[-1][1], steps)\n","          writer.add_scalar(\"loss/feature_matching\", costs[-1][2], steps)\n","          writer.add_scalar(\"loss/mel_reconstruction\", costs[-1][3], steps)\n","          steps += 1\n","          "],"execution_count":null,"outputs":[]}]}